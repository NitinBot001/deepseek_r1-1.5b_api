name: Persistent Ollama API via LocalTunnel

on:
  workflow_dispatch:

jobs:
  run-ollama:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # Maximum allowed time (6 hours)

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sudo sh
          echo "$HOME/.ollama/bin" | sudo tee -a /etc/profile
          sudo chmod +x /usr/local/bin/ollama

      - name: Verify Ollama installation
        run: sudo ollama --version

      - name: Pull Deepseek-R1 model
        run: sudo ollama pull deepseek-r1:1.5b

      - name: Start Ollama server
        run: |
          sudo nohup ollama serve > /var/log/ollama.log 2>&1 &

      - name: Wait for Ollama to start
        run: sleep 10

      - name: Install LocalTunnel
        run: sudo npm install -g localtunnel

      - name: Start LocalTunnel and Capture URL
        run: |
          sudo nohup lt --port 11434 > /var/log/lt.log 2>&1 &
          sleep 10  # Give LocalTunnel time to initialize
          sudo cat /var/log/lt.log | grep -o 'https://[a-zA-Z0-9.-]*\.loca\.lt' | sudo tee /var/log/lt_url.txt || echo "LocalTunnel failed"

      - name: Display LocalTunnel URL
        run: sudo cat /var/log/lt_url.txt

      - name: Keep Workflow Running
        run: |
          while true; do sleep 600; done
