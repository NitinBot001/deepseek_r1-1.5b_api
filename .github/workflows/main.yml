name: Persistent Ollama API via LocalTunnel

on:
  workflow_dispatch:

jobs:
  run-ollama:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # Maximum allowed time (6 hours)

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          echo "$HOME/.ollama/bin" >> $GITHUB_PATH

      - name: Verify Ollama installation
        run: ollama --version

      - name: Pull Deepseek-R1 model
        run: ollama pull deepseek-r1:1.5b

      - name: Start Ollama server
        run: |
          nohup ollama serve > ollama.log 2>&1 &

      - name: Wait for Ollama to start
        run: sleep 10

      - name: Install LocalTunnel
        run: npm install -g localtunnel

      - name: Start LocalTunnel in tmux session
        run: |
          tmux new-session -d -s tunnel 'while true; do sudo lt --port 11434 --subdomain ollama-deepseek-rjehe1; sleep 15; done'

      - name: Display LocalTunnel URL
        run: |
          sleep 10  # Give some time for localtunnel to start
          curl -s localhost:11434/api/tags || echo "Ollama API not reachable"

      - name: Keep Workflow Running
        run: |
          echo "Keeping the workflow alive..."
          while true; do sleep 600; done
